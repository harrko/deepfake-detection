{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deepfake classification"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The video frames are classified using Inception Net in Keras. A confusion matrix is plotted to visualize the results on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages.\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, plot_confusion_matrix\n",
    "from tensorflow import keras as K\n",
    "from tensorflow.keras.layers import Dense, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if GPU is available.\n",
    "tf.test.is_gpu_available(\n",
    "    cuda_only=False, min_cuda_compute_capability=None\n",
    ")\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Inception Net V3 pretrained on ImageNet.\n",
    "inception_model = K.applications.InceptionV3(\n",
    "    weights='imagenet',  # Load weights pre-trained on ImageNet.\n",
    "    input_shape=(200, 200, 3),\n",
    "    include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use transfer learning, set base model to untrainable.\n",
    "inception_model.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add MaxPooling layer and binary classification linear layer.\n",
    "x = inception_model.output\n",
    "x = K.layers.GlobalMaxPooling2D()(x)\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "model = Model(inputs=inception_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model.\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 66762 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Generate dataloaders.\n",
    "train_datagen = ImageDataGenerator()\n",
    "val_datagen = ImageDataGenerator()\n",
    "test_datagen = ImageDataGenerator()\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'D:/data/facefor/FaceForensics_compressed/train200',  # this is the target directory  \n",
    "        batch_size=16,\n",
    "        class_mode='binary',\n",
    "    shuffle=True)\n",
    "\n",
    "val_generator = test_datagen.flow_from_directory(\n",
    "        'D:/data/facefor/FaceForensics_compressed/val200',  # this is the target directory  \n",
    "        batch_size=16,\n",
    "        class_mode='binary')\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        'D:/data/facefor/FaceForensics_compressed/test200',  # this is the target directory  \n",
    "        batch_size=16,\n",
    "        class_mode='binary',\n",
    "shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model.\n",
    "model.fit(x=train_generator, \n",
    "    epochs=15,\n",
    "    verbose=1,\n",
    "    shuffle=True,\n",
    "    validation_data = val_generator\n",
    ")\n",
    "model.save_weights('ffinception2.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "4899/4899 [==============================] - 395s 81ms/step - loss: -5.1543 - accuracy: 0.6958\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[-5.154281998279431, 0.6958114]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model on the test set.\n",
    "model.evaluate(\n",
    "    x=test_generator,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "980/980 [==============================] - 63s 64ms/step\n"
     ]
    }
   ],
   "source": [
    "# Make prediction on the test set.\n",
    "preds = model.predict(\n",
    "    x=test_generator,\n",
    "    verbose=1,\n",
    "    steps=None,\n",
    "    callbacks=None,\n",
    "    max_queue_size=10,\n",
    "    workers=1,\n",
    "    use_multiprocessing=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate aand display confusion matrix.\n",
    "cm = confusion_matrix(test_generator.classes, preds)\n",
    "df_cm = pd.DataFrame(cm)\n",
    "sn.heatmap(df_cm, annot=True, cmap=\"YlGnBu\",fmt=\"g\", annot_kws={\"size\": 16}) # font size\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00     11215\n",
      "           1       0.98      0.99      0.99      4460\n",
      "\n",
      "    accuracy                           0.99     15675\n",
      "   macro avg       0.99      0.99      0.99     15675\n",
      "weighted avg       0.99      0.99      0.99     15675\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print precision, recall and f1 score.\n",
    "print(classification_report(test_generator.classes, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GradCam implementation is based on paper Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization\n",
    "def heatmap(dirname):\n",
    "    count = 0\n",
    "    for img in glob.glob(f\"{dirname}/*.jpg\"):\n",
    "        face_org = cv2.imread(img)\n",
    "        face_res = cv2.resize(face_org, (200,200))\n",
    "        img = image.load_img(img, target_size=(200, 200))\n",
    "        x = image.img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        x = preprocess_input(x)\n",
    "        preds = model.predict(x=x,\n",
    "        verbose=1,\n",
    "        steps=None,\n",
    "        callbacks=None,\n",
    "        max_queue_size=10,\n",
    "        workers=1,\n",
    "        use_multiprocessing=False,\n",
    "        )\n",
    "        crop_output = model.output[:, 0]\n",
    "\n",
    "        last_conv_layer = model.get_layer('block14_sepconv1')\n",
    "\n",
    "        grads = K.backend.gradients(crop_output, last_conv_layer.output)[0]\n",
    "    \n",
    "        pooled_grads = K.backend.mean(grads, axis=(0, 1, 2))\n",
    "\n",
    "        iterate = K.backend.function([model.input], [pooled_grads, last_conv_layer.output[0]])\n",
    "\n",
    "        pooled_grads_value, conv_layer_output_value = iterate([x])\n",
    "\n",
    "        for i in range(512):\n",
    "            conv_layer_output_value[:, :, i] *= pooled_grads_value[i]\n",
    "\n",
    "        heatmap = np.mean(conv_layer_output_value, axis=-1)\n",
    "        heatmap = np.maximum(heatmap, 0)\n",
    "        heatmap /= np.max(heatmap)\n",
    "  \n",
    "        img = face_org\n",
    "\n",
    "        heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
    "\n",
    "        heatmap = np.uint8(255 * heatmap)\n",
    "\n",
    "        heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "\n",
    "        superimposed_img = heatmap * 0.4 + img\n",
    "        \n",
    "# Replace path with path to folder where to store the overlay images\n",
    "        cv2.imwrite('WRITE PATH/%imposed.jpg' % count, superimposed_img)\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace path with the path to source folder\n",
    "heatmap('SOURCE PATH')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
